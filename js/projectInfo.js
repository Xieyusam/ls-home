const project9Introduction = `
https://design-ailab.com/project/2

Low-carbon campus is a service plan that combines scientific technology and humanities and arts to achieve the goal of a sustainable ecological campus. It guides teachers and students to practice low-carbon behaviors through behavioral science methods, spreads the concept of green and low-carbon through artistic actions, and leads social low-carbon fashion through innovative scene experiences. It has the advantages of being lightweight, low-threshold, and inclusive, aiming to explore and construct a low-carbon campus model that is suitable for local conditions, integrates science and art, and is organically regenerative.

I. Concept First: Proposes the design proposition of "the academy is the community, low-carbon is fashion". With the goal of achieving a sustainable ecological campus, it is based on an international perspective and local practice, from vision construction to design methods, from content innovation to practical paths, from teacher-student resonance to resource sharing, aiming to explore and construct a more vivid, more charming, and more beautiful ecological sustainable development plan, providing a low-carbon campus model that is suitable for local conditions, integrates science and art, and is organically regenerative.

II. Architectural Breakthrough: It's not just about energy consumption, but also a systematic reconstruction of lifestyles and production methods. Using innovative design thinking to integrate resources such as technology, tools, and communities, it guides teachers and students to "proactively be low-carbon" through behavioral science methods, and constructs a low-carbon campus system architecture with the path of "data insight - behavior guidance - ecological network".

III. Technology Activation: Focusing from user needs to the organic renewal of big data and intelligent hardware. Fully explore the campus energy and carbon data resources, integrate information technology with user service touchpoints, from defining low-carbon campus indicators to monitoring and analyzing the energy consumption of dormitories, and collaborate with digital platforms to develop digital tools and design innovative digital experience content for multi-level organizational relationships.

IV. Scene Creation: From daily innovation in living, teaching, and exhibition to new social interactions. Create a green, healthy, and sustainable campus learning and living scene system, link a campus carbon inclusive system driven by low-carbon creation, low-carbon behavior, low-carbon rights, and low-carbon blockchain, and create a low-carbon lifestyle, create low-carbon economic value, and promote low-carbon as a new fashion that drives the transformation and development of the whole society.

World Summit on the Information Society (WSIS Prizes) Electronic Environment Category Champion Award 2022, selected as one of "Hangzhou's Top Ten Low-Carbon Scenes" in 2022, selected for the "Fourth China Design Exhibition" in 2022, selected in "Carbon Peak and Carbon Neutrality in the Digital Age" "Chinese Wisdom and Chinese Solutions" in 2022, and shortlisted for the IF Social Impact 2022.



`;

const project1 = {
  id: 1,
  coverImage: "./image/project/project-1.png",
  sortOrder: 1,
  category: "Accessibility",
  title: "Hearing the bullseye",
  titleDescription: '(CSCW’24, CHI PLAY’24, ASSETS’24), Waitting Publication.',
  titleLink: [
    { name: "PDF", link: "./file/CHI_Play2024.pdf" },
  ],
  time: "2021-2022",
  anthor:
    "Shan Luo*, Yan Chen, Hanxiang Fang, Lipin Luo, Longfei Zhou, Yun Wang, Jihong Zhu, Lu Lin, Jianan Liu, Botao Hu.",
  award: [
    {
      id: 1,
      time: "June 15 2021",
      desc: "Beyond the Realm Exhibition: Design Intellegence Center Honorable Mentions, Hearing The Bullseye.",
      link: "",
      place: "",
    },
    {
      id: 2,
      time: "Dec 22 2021",
      desc: "Honorable Mention, DIA China Design Intelligent Manufacturing Award.",
      link: "",
      place: "",
    },
    {
      id: 3,
      time: "Dec 15 2022",
      desc: "4th China Design Exhibition and Public Art Special Exhibition, Hearing The Bullseye.",
      link: "",
      place: "",
    },
    {
      id: 4,
      time: "March 15 2022",
      desc: "Dutch Design Week, Hearing The Bullseye.",
      link: "",
      place: "",
    },
    {
      id: 5,
      time: "May 15 2022",
      desc: "Finalist, OPPO Global ”Smile Proposal” Finalist Award.",
      link: "",
      place: "",
    },
    {
      id: 6,
      time: "Jan 15 2022",
      desc: "Bow, Listening Arrow. Design patent, Application No: 202130290451.4.",
      link: "",
      place: "",
    },
    {
      id: 7,
      time: "Dec 25 2022",
      desc: "Gold Award, 13th International User Experience Competition (UXDA, UXPA).",
      link: "",
      place: "",
    },
    {
      id: 8,
      time: "Dec 27 2023",
      desc: "ShangHai West Bund Art And Design Expo, A Live-action CS Sound Shooting Game App. ",
      link: "",
      place: "",
    },
    {
      id: 9,
      time: "Dec 15 2023",
      desc: "Archery with the Blind. Health Development: Design Empowerment. Peking University Press’23.",
      link: "",
      place: "",
    },
    {
      id: 10,
      time: "Jan 14 2024",
      desc: "A method for enabling fair archery competition between blind and sighted individuals. Utility model patent, No: ZL202110530004.0.",
      link: "",
      place: "",
    },
    {
      id: 11,
      time: "May 15 2024",
      desc: "Demostrating: Hearing the Bullseye- An Auditory-Cued Archery Exergame for the Visually Impaired and Their Sighted Family and Friends. CHI’24 workshop.",
      link: "",
      place: "",
    },
    {
      id: 12,
      time: "May 15 2024",
      desc: "Designing a Safe Auditory-Cued Archery Exertion Game for the Visually Impaired and Sighted to Enjoy Together. ASSETS’24 poster.",
      link: "",
      place: "",
    },
    {
      id: 13,
      time: "June 15 2024",
      desc: "Hearing the Bullseye: An Auditory-Cued Archery Exergame for the Visually Impaired and Their Sighted Family and Friends.CHI PLAY’24 .",
      link: "",
      place: "",
    },
    {
      id: 14,
      time: "June 18 2024",
      desc: "Hearing the Bullseye: Demonstrating the Design of an Auditory-Cued Archery Exergame for the Visually Impaired and Their Sighted Family and Friends. CSCW’24 .",
      link: "",
      place: "",
    }
  ],
  introduction: {
    text: 'How can blind and sighted individuals play together? The natural disparity in visual abilities often poses challenges for fair competition in social play. This can diminish the confidence of visually impaired (VI) individuals and reduce engagement for sighted players. While previous literature has incorporated fairness design strategies for the VI, we additionally aim to address the potential problem of boredom for sighted players by providing enhanced visual feedback without compromising fairness as a novel design strategy. We present "Hearing the Bullseye", an archery exergame designed for harmonious play between VI individuals and their sighted family and friends. Players use a bow equipped with an infrared sensor, allowing them to target an unseen bullseye using sound rather than sight. An empirical study involving 18 sighted and VI participants demonstrated that the design strategies used in "Hearing the Bullseye" effectively promote social engagement among both groups while ensuring fair competition. ',
    buttonGroup: [],
  },
  contant: [
    {
      type: "Title",
      text: "Academic Presentation",
    },
    {
      type: "miniTitle",
      text: "CHI’24 workshop",
    },
    {
      type: "video",
      text: "",
      link: "https://www.youtube.com/embed/FiHRtG3qujU?si=v5yrprRAUCS0DgC5",
    },
    {
      type: "Title",
      text: "Project Video",
    },
    {
      type: "video",
      text: "",
      link: "https://www.youtube.com/embed/-utGROi31nw?si=UgHOgTWnAhYeDeWU",
    },
    {
      type: "Title",
      text: "Renderings",
    },
    {
      type: "img",
      link: "./image/detail/1/1.png",
    },
    {
      type: "img",
      link: "./image/detail/1/2.png",
    },
    {
      type: "img",
      link: "./image/detail/1/3.png",
    },
  ],
};

const project2 = {
  id: 2,
  coverImage: "./image/project/project-2.png",
  sortOrder: 2,
  category: "Accessibility",
  title: "Family-centered simple sound shooting interaction game",
  time: "2023",
  anthor: "Shan Luo*, Yun Wang.",
  award: [
    {
      id: 1,
      time: "Dec 27 2023",
      desc: "ShangHai West Bund Art And Design Expo, A Live-action CS Sound Shooting Game App.",
      link: "",
      place: "Hangzhou",
    },
    {
      id: 2,
      time: "July 15 2023",
      desc: "Hong Kong University of Science and Technology, A Live-action CS Sound Shooting Game.",
      link: "",
      place: "Guangzhou",
    },
    {
      id: 3,
      time: "July 01 2023",
      desc: "Research on the design of a live-action CS sound shooting game app under the concept of joint play for the visually impaired and sighted. RMB10000. National Innovation and Entrepreneurship Project: 202210355061",
      link: "",
      place: "Guangzhou",
    },
  ],
  introduction: {
    text: `It is our innate ability to freely engage in recreational sports with peers, but the visually impaired need more time, energy and courage to achieve it. At the same time, as "normal people", we usually act as passive companions in a "accompanying" state. Design how to use AI technology to empower the sports ability of the disabled; how to achieve equality and initiative in the process of swimming together, rather than a compromise of one party. Hear the bullseye is a cs shooting APP game that uses AI yolo visual algorithm technology to find the bull's-eye or move the player's position with real-time auditory and tactile feedback, so that the visually impaired and ordinary people can experience the sound version of the CS shooting APP game by using ears instead of eyes . Players on both sides can use the mobile phone camera to identify the color "bullseye" of the enemy's movement. Identify its location by sound, and complete the shooting in combination with the sound interaction of the APP. The interactive mode of game design can increase players' interest in sports games, and at the same time promote mutual understanding and communication between visually impaired and sighted people. Achieve an inclusive society.`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "Title",
      text: "Project Video",
    },
    {
      type: "video",
      text: "",
      link: "https://www.youtube.com/embed/MtPIW9B8US4?si=98VZjxO3_pDYgtJ1",
    },
    {
      type: "Title",
      text: "Renderings",
    },
    {
      type: "img",
      link: "./image/detail/2/1.png",
    },
    {
      type: "img",
      link: "./image/detail/2/2.png",
    },
    {
      type: "img",
      link: "./image/detail/2/3.png",
    },
    {
      type: "img",
      link: "./image/detail/2/4.png",
    },
    {
      type: "img",
      link: "./image/detail/2/5.png",
    },
  ],
};

const project3 = {
  id: 3,
  coverImage: "./image/project/project-3.png",
  sortOrder: 3,
  category: "Accessibility",
  title: "Makeup Box for the Blind",
  time: "2021",
  anthor: "Wang Xinran, Lv Jiuya, Zheng Bowen, Qin Zihan, Shan Luo*.",
  award: [
    {
      id: 1,
      time: "May 15 2021",
      desc: "Alibaba Design Week, Makeup Box for the Blind",
      link: "",
      place: "Hangzhou",
    },
  ],
  introduction: {
    text: `This is a makeup box for the blind developed in 2021. It uses a camera to recognize facial features, including lips, eyes, and facial contours, and applies AI small sample models to provide makeup suggestions for the blind. Due to the slow development of large language models in the early stages of the project, few-shot learning was used for training at that time. Looking back with today's technological advancements, this work still holds historical significance. It was the first time we realized that the pursuit of beauty is not related to sensory perception but is an intrinsic human impulse. I joined the team in the later stages of the project and was responsible for completing the research work related to the thesis.`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "Title",
      text: "Live demonstration at the exhibition",
    },
    {
      type: "miniTitle",
      text: "Alibaba Design Week 2021.",
    },
    {
      type: "video",
      text: "",
      link: "https://www.youtube.com/embed/D-7weVKuN_8?si=tkBtncWEpPz0okJu",
    },
    {
      type: "Title",
      text: "Renderings",
    },
    {
      type: "img",
      link: "./image/detail/3/1.png",
    },
    {
      type: "img",
      link: "./image/detail/3/2.png",
    },
    {
      type: "img",
      link: "./image/detail/3/3.png",
    },
    {
      type: "img",
      link: "./image/detail/3/4.png",
    },
  ],
};

const project4 = {
  id: 4,
  coverImage: "./image/project/project-4.png",
  sortOrder: 4,
  category: "Accessibility",
  title: "Hearing the Smile” —Scoring Spontaneous Social Scenes for the Visually Impaired.",
  greyTitle: '',
  time: "2025",
  anthor: "Shan Luo*, Jinlin Miao, Yue Chen, Hongyue Wang, Xin Tong. ",
  titleDescription: 'DIS(submitted) Chinese CHI.',
  titleDescriptionLink: 'https://doi.org/10.1145/3775021.3787093',
  titleLink: [
    { name: 'PDF', link: './file/ScenScene___CHI_2025_Paper_compressed.pdf' }
  ],
  award: [],
  introduction: {
    text: `Interpersonal warmth is a key signal that helps strangers build relationships. However, BLV individuals lack access to such cues, limiting their ability to perceive warmth and establish trust. Prior work has primarily supported BLV users through auditory or textual cues during conversations, but overlooked the ice-breaking connection process—how BLV individuals can proactively sense warmth before talking. We conducted fomative study to explore the interaction modality chosen by BLV people and the challenges they face in the ice-breaking. Based on design goals from formative study, we propose \textit{Hearing the Smile}, a smart glasses prototype that translates warmth into AI-generated personalized melodies. In a user study with six BLV users, we found that \textit{Hearing the Smile} enabled BLV users to perceive and distinguish different levels of warmth. This work demonstrates how augmenting non-visual social signals can expand interpersonal social opportunities for BLV individuals, contributing design insights for accessible and affective human–AI interaction.`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/4/8.png",
    }, {
      type: "video",
      link: "https://www.youtube.com/embed/zL2LgTYP1hE?si=x-bCSM4TbIVP4ZAX",
    },{
      type: "img",
      link: "./image/detail/4/9.png",
    },{
      type: "img",
      link: "./image/detail/4/10.png",
    },{
      type: "img",
      link: "./image/detail/4/11.png",
    },{
      type: "img",
      link: "./image/detail/4/12.png",
    },{
      type: "img",
      link: "./image/detail/4/13.png",
    },
  ],
};

const project5 = {
  id: 5,
  coverImage: "./image/project/project-5.png",
  sortOrder: 9,
  category: "Interesting",
  title: "Mindos.AI",
  time: "2023.07-12",
  anthor: "Shan Luo*.",
  award: [],
  introduction: {
    text: `During my work hours, I mainly did two things. The first thing was to write a design planning proposal for the company, and the second was to develop products. The planning proposal included my approach and future predictions for the entire AI startup. The product developed today seems more like an intermediate simulator leading to a new paradigm of design. Most users who come in don't know how to use it, wondering how to play with this thing? Mindos, like an art piece, tells investors an incredibly perfect story of the future AI OS. Here, memories can be strung into a chain, and the personal assistant can help you with anything, even call his friends to help you complete tasks together...`,
    buttonGroup: [
      { text: "DOWNLOAD MindOS Design Strategy Report", link: "./file/mindos产品分析报告.pdf" },
      { text: "MindOS .com", link: "https://www.mindos.com/mebot" },
    ],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/5/1.png",
    },
    {
      type: "img",
      link: "./image/detail/5/2.png",
    },
    {
      type: "img",
      link: "./image/detail/5/3.png",
    },
    {
      type: "img",
      link: "./image/detail/5/4.png",
    },
    {
      type: "img",
      link: "./image/detail/5/5.png",
    },
    {
      type: "img",
      link: "./image/detail/5/6.png",
    },
  ],
};

const project6 = {
  id: 6,
  coverImage: "./image/project/project-6.png",
  sortOrder: 8,
  category: "Interesting",
  title: "Granary Culture Design Image Research",
  time: "2022.07-12",
  anthor: "Shan Luo*.",
  award: [],
  introduction: {
    text: `The main work of the Granary Culture Image Research is to trace the historical context of granary culture, and finally to focus on the architecture, visual system, and landscape gardening of the granaries in Zhejiang. In this project, I systematically learned about knowledge diagram thinking, literature research, and integration skills.`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/6/1.png",
    },
    {
      type: "img",
      link: "./image/detail/6/2.png",
    },
    {
      type: "img",
      link: "./image/detail/6/3.png",
    },
    {
      type: "img",
      link: "./image/detail/6/4.png",
    },
    {
      type: "img",
      link: "./image/detail/6/5.png",
    },
    {
      type: "img",
      link: "./image/detail/6/6.png",
    },
    {
      type: "img",
      link: "./image/detail/6/7.png",
    },
    {
      type: "img",
      link: "./image/detail/6/8.png",
    },
    {
      type: "img",
      link: "./image/detail/6/9.png",
    },
    {
      type: "img",
      link: "./image/detail/6/10.png",
    },
  ],
};

const project7 = {
  id: 7,
  coverImage: "./image/project/project-9.png",
  sortOrder: 12,
  category: "Interesting",
  title: "Mood Meta",
  time: "2022.04-12",
  anthor: "Shan Luo*.",
  award: [],
  introduction: {
    text: `This is an unfinished work, a technical path that several partners have been researching for a long time, which ultimately ended in failure. Unexpectedly, when we posted the video on social media, it was surprisingly well-received by many young people. The comments and likes we received made us realize that students, after detaching from project resources, have the opportunity to be seen by society not only through galleries, topics, papers, but also through self-media.`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "video",
      link: "https://www.youtube.com/embed/Bb7MIe4E7kw?si=jWjBRJ5gu48WpRTS",
    },
  ],
};

const project8 = {
  id: 8,
  coverImage: "./image/project/project-10.png",
  sortOrder: 13,
  category: "Interesting",
  title: "Sky Camping",
  time: "2022.04-12",
  anthor: "Shan Luo*.",
  award: [],
  introduction: {
    text: `Did everyone see the magic carpet of the princess in Aladdin's lamp when they were young? In 2022, I was assigned to tutor undergraduate students in their design creations, and at that time the students proposed the theme of sky camping. So we began to fantasize about having such a magic carpet in real life. Although the final model was a tent hanging on a tree, we depicted an imagination, "When the wind blows, the space can control the transparency of the material according to the external sound, making us feel as if we were flying on the magic carpet and were disturbed by a gust of wind."`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "video",
      link: "https://www.youtube.com/embed/HQzjQopNo7w?si=0xRKgxSstKvVv_sa",
    },
    {
      type: "img",
      link: "./image/detail/8/1.png",
    },
  ],
};

const project9 = {
  id: 9,
  coverImage: "./image/project/project-7.png",
  sortOrder: 10,
  category: "Channel",
  title: "Sky Camping",
  time: "2022.04-12",
  anthor: `Wang Yun, Chen Yunjia,  Du Liang, Feng Ruiyun, Shen Xinyu, Chen Xianxu, Mao Mengyuan, Zhao Yi, Lian Yiqing, Luo Shan, Ding Yuxin, Cai Herui, Sun Danshan
  External Partner: Alibaba Cloud`,
  award: [
    {
      id: 1,
      time: "May 15 2021",
      desc: "Finalist, World Summit on the Information Society (WSIS) Award Nomination.",
      link: "",
      place: "Hangzhou",
    },
  ],
  introduction: {
    text: project9Introduction,
    buttonGroup: [],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/9/1.png",
    },
    {
      type: "img",
      link: "./image/detail/9/2.png",
    },
  ],
};

const project10 = {
  id: 10,
  coverImage: "./image/project/project-8.png",
  sortOrder: 11,
  category: "Channel",
  title: "D-WILL Design Lecture Hall",
  time: "2022.04-12",
  anthor: `Yun Wang, Liang Du, Shan Luo, Kexin Cheng `,
  award: [],
  introduction: {
    text: `I am at the dwill Design Lecture Hall with the theme "See the World Through the Eyes of Others." I have successively undertaken various roles such as academic assistant, academic host, and corporate study tours, and organized various communities for the new generation of designers. From Chiba University in Japan to overseas botanists, to China's intelligent manufacturing robots, I have learned a great deal of knowledge at the forefront of design and have gained a lot.`,
    buttonGroup: [
      {
        text: "YOUTUBE",
        link: "https://youtube.com/@d-willlecture3000?si=9JBobiSXW3tNSagv",
      },
    ],
  },
  contant: [
    {
      type: "video",
      link: "https://www.youtube.com/embed/wssPzcwr7SM?si=iCu4WnARY67uKlh0",
    },
    {
      type: "img",
      link: "./image/detail/10/1.png",
    },
    {
      type: "img",
      link: "./image/detail/10/2.png",
    },
    {
      type: "img",
      link: "./image/detail/10/3.png",
    },
    {
      type: "img",
      link: "./image/detail/10/4.png",
    },
  ],
};

const project11 = {
  id: 11,
  coverImage: "./image/project/project-12.png",
  sortOrder: 14,
  category: "Channel",
  title: "Blind Design Podcast",
  time: "2021-",
  anthor: `Shan Luo, Liping Luo`,
  award: [],
  introduction: {
    text: `Because I love design so much and have access to a lot of design resources, I started a podcast with a friend called "Blind Design Talks." From time to time, we invite many big names from different industries to share their perspectives. The most memorable was in 2022 when we invited an engineering teacher from NVIDIA to share with us what a large model is, and we invited a friend from the Durex marketing team to share design strategies in the market...`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/11/1.png",
      style: 'width: 518px;height: 864px;margin-left:342px;'
    },
  ],
};

const project12 = {
  id: 12,
  coverImage: "./image/project/project-13.png",
  sortOrder: 5,
  category: "Accessibility",
  title: "EmojiFan: Designing a Social Interface Supporting Facial Expression Interaction for Blind and Low Vision People in Party Settings",
  time: "2025",
  anthor: `Jinlin Miao*,  Shan Luo*, Yue Chen, Hongyue Wang, Rina R. Wehbe.`,
  award: [],
  introduction: {
    text: `Facial expression interactions play a crucial role in fostering social bonds and expressing emotions. However, in the dynamic, fast-paced, and noisy environments of parties, various factors hinder blind and low-vision (BLV) individuals from engaging fully in facial expression interactions. While previous research has explored how BLV users can convey emotions through non-verbal visual cues, it has largely overlooked the challenges they face in engaging with facial expressions after perceiving these cues. To address this gap, we conducted a formative study with 10 BLV users to identify their challenges and expectations regarding facial expression interactions in party settings. Guided by these insights, we developed \textit{EmojiFan}, an AI-powered smart fan designed to offer a personalized representation of facial expressions through dynamic, expressive emojis. Finally, we carried out an in-the-field study with 6 BLV participants and 8 sighted social partners to examine the effectiveness of \textit{EmojiFan} in enhancing facial-expression interactions during parties. Overall, our goal is to empower BLV individuals' autonomy to actively participate in social interactions through digital facial expression, thereby contributing new insights for the accessibility community on designing expressive, socially responsive assistive technologies.`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/12/1.png",
    },{
      type:"video",
      link: "https://www.youtube.com/embed/tUyL3eht8tI?si=Sesm6I4bwRALkHPK",
    },{
      type:"img",
      link: "./image/detail/12/2.png",
    },{
      type:"img",
      link: "./image/detail/12/3.png",
    }
  ],
};
const project13 = {
  id: 13,
  coverImage: "./image/project/project-14.png",
  sortOrder: 6,
  category: "Game",
  title: "TunTun Diary: Exploring AI-Generated Storytelling and Virtual Companionship for Nightmare Relief",
  time: "2025",
  anthor: `Zixin Wang, Shan Luo , Kesheng Shenlv, Siyu Chen, Yunxi Cai, Long Ling, Muhan Xu...`,
  award: [],
  linkGroup: [
    {
      text: "SIGGRAPH ASIA 25 POSTER",
      link: "https://dl.acm.org/doi/10.1145/3757374.3771484",
    },{
      text: "App Store",
      link: "https://apps.apple.com/cn/app/%E5%90%9E%E5%90%9E%E6%97%A5%E8%AE%B0/id6744860687",
    }
  ],
  introduction: {
    text: `Nightmares disrupt sleep and heighten daytime anxiety, yet therapeutic support is often hard to access due to limited clinician availability, cost, and clinical framing. We propose TunTun Diary, a mobile game in which an alien puppy named TunTun “eats” players’ nightmares and returns gentle, comic-style retellings. The system uses generative AI to reinterpret users' nightmare descriptions into positive narratives. Through simple text-based dream input and playful pet interactions, players form an emotional bond with TunTun as a safe and supportive companion for coping with negative dreams. In a preliminary deployment with 20 young adults, participants reported emotional relief and increased comfort after engaging with TunTun’s transformed dream comics, often describing the experience as both soothing and playful. These findings highlight how integrating therapy-inspired reframing with interactive storytelling and virtual companionship can lower barriers to everyday emotional support. By illustrating a novel application of AI-based visual storytelling in game contexts, TunTun Diary opens opportunities for future research at the intersection of visual computing, affective interaction, and game design. `,
    buttonGroup: [],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/13/1.png",
    },{
      type: "img",
      link: "./image/detail/13/2.png",
    },{
      type:"video",
      link: "https://www.youtube.com/embed/xtO-DPJx4m4?si=f7f88MVv79PloLDD",
    }
  ],
};
const project14 = {
  id: 14,
  coverImage: "./image/project/project-15.png",
  sortOrder: 7,
  category: "More than Human",
  title: "Asking Water with Stones: Designing Playful Dialogues with Water System to Build Connection between Human and Water Ecosystems",
  time: "2025",
  anthor: `Shan Luo , Weitao JIang, jinlin Miao, Hongyue Wang Jiangnan Xu, Çağlar Genç, Oğuz 'Oz' Buruk`,
  award: [],
  linkGroup: [
    {
      text: "TEI 26",
      link: "https://doi.org/10.1145/3731459.3779351",
    }
  ],
  introduction: {
    text: `The more-than-human field has contributed numerous opportunities for interacting with nature, animals, plants, and microorganisms. However, few studies have examined water ecosystems. Current water-related work primarily treats water as a medium for human-centered activities, rarely positioning water as an interactive subject. Building upon prior research, we explore how to better integrate water more playfully into digital-physical interactions as an interactive subject. We designed and developed “Water’s Echo”, an AI-powered public installation that enables human-water communication through a playful stone-throwing dialogue. We conducted a field study at a local pond, recruiting 15 residents to participate in \textit{Water’s Echo}—a playful conversational interaction. Our findings indicate that this playful dialogue approach raises participants' awareness and understanding of surrounding aquatic environments. This research provides insights for design researchers to establish engaging water ecology interactions across cultural communities, promoting a More-than-human perspective in re-examining human-nature relationships.`,
    buttonGroup: [],
  },
  contant: [
    {
      type: "img",
      link: "./image/detail/14/1.png",
    },{
      type: "img",
      link: "./image/detail/14/2.png",
    },{
      type:"video",
      link: "https://www.youtube.com/embed/X_E12_jcGMI?si=_LIdJNwNrNr3RwTU",
    }
  ],
};

var projectInfoData = {
  project1,
  project2,
  project3,
  project4,
  project5,
  project6,
  project7,
  project8,
  project9,
  project10,
  project11,
  project12,
  project13,
  project14,
};
